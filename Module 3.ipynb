{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb93556-88b9-4acb-83d5-c864a06717f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "|details-start|\n",
      "**References**\n",
      "|details-split|\n",
      "\n",
      "- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "  Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "  Structure and Classification Rule for Recognition in Partially Exposed\n",
      "  Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "  Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "  on Information Theory, May 1972, 431-433.\n",
      "- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "  conceptual clustering system finds 3 classes in the data.\n",
      "- Many, many more ...\n",
      "\n",
      "|details-end|\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "5                5.4               3.9                1.7               0.4\n",
      "6                4.6               3.4                1.4               0.3\n",
      "7                5.0               3.4                1.5               0.2\n",
      "8                4.4               2.9                1.4               0.2\n",
      "9                4.9               3.1                1.5               0.1\n",
      "   irisType\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "5         0\n",
      "6         0\n",
      "7         0\n",
      "8         0\n",
      "9         0\n",
      "irisType\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the iris data to memory\n",
    "iris = load_iris()\n",
    "\n",
    "# The loaded iris is a dictionary - so check it\n",
    "print(iris.keys())\n",
    "\n",
    "# You can print the description of the dataset\n",
    "print(iris['DESCR'])\n",
    "\n",
    "# Convert the loaded data and targets into a dataframe and print the first ten rows.\n",
    "X = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "print(X.head(10))\n",
    "\n",
    "Y = pd.DataFrame(data=iris.target, columns = ['irisType'])\n",
    "print(Y.head(10))\n",
    "\n",
    "# Explore the number of classes in the target set\n",
    "print(Y['irisType'].value_counts())\n",
    "\n",
    "# The names of the classes(i.e. species in the iris dataset)\n",
    "print(iris.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c15165-ce62-44c8-bf98-6da38f746249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Absolute Error is: 2.0\n",
      "The Mean Square Error is: 5.0\n",
      "The Categorical Cross Entropy Loss is: 0.2876821\n",
      "The Sparse Categorical Cross Entropy Loss is: 0.28768212\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError, CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "\n",
    "# Define y_true and y_pred for a regression task\n",
    "y_true = np.array([1., 0.])\n",
    "y_pred = np.array([2., 3.])\n",
    "\n",
    "# Compute and print the Mean Absolute Error (MAE)\n",
    "mae_loss = MeanAbsoluteError()\n",
    "print(\"The Mean Absolute Error is:\", mae_loss(y_true, y_pred).numpy())\n",
    "\n",
    "# Compute and print the Mean Square Error (MSE)\n",
    "mse_loss = MeanSquaredError()\n",
    "print(\"The Mean Square Error is:\", mse_loss(y_true, y_pred).numpy())\n",
    "\n",
    "# Define y_true and y_pred for a classification task\n",
    "# Use one-hot vector representation\n",
    "y_true = np.array([[0, 1, 0], [1, 0, 0]])\n",
    "y_pred = np.array([[0.15, 0.75, 0.1], [0.75, 0.15, 0.1]])\n",
    "\n",
    "# Compute and print the categorical cross-entropy loss\n",
    "cross_entropy_loss = CategoricalCrossentropy()\n",
    "print(\"The Categorical Cross Entropy Loss is:\", cross_entropy_loss(y_true, y_pred).numpy())\n",
    "\n",
    "# Use label-encoded representation for the class\n",
    "y_true = np.array([1, 0])\n",
    "y_pred = np.array([[0.15, 0.75, 0.1], [0.75, 0.15, 0.1]])\n",
    "\n",
    "# Compute and print the sparse categorical cross-entropy loss\n",
    "cross_entropy_loss = SparseCategoricalCrossentropy()\n",
    "print(\"The Sparse Categorical Cross Entropy Loss is:\", cross_entropy_loss(y_true, y_pred).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99c2a95-4131-46c2-8fbe-6a8a0bd91439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted v1: 1.6\n",
      "Predicted v2: 6.0\n",
      "Mean Squared Error for v1: 0.0\n",
      "Mean Squared Error for v2: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Assignment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming vt, r1, and r2 are given\n",
    "vt = 10\n",
    "r1 = 2\n",
    "r2 = 3\n",
    "\n",
    "# Calculate v1 and v2\n",
    "v1 = (vt - r1) / (r1 + r2)\n",
    "v2 = (vt * r2) / (r1 + r2)\n",
    "\n",
    "# Prepare the data for linear regression\n",
    "X = [[r1, r2]]\n",
    "y_v1 = [v1]\n",
    "y_v2 = [v2]\n",
    "\n",
    "# Train the linear regression models\n",
    "reg_v1 = LinearRegression().fit(X, y_v1)\n",
    "reg_v2 = LinearRegression().fit(X, y_v2)\n",
    "    \n",
    "# Predict v1 and v2 for given vt, r1, and r2\n",
    "predicted_v1 = reg_v1.predict([[r1, r2]])\n",
    "predicted_v2 = reg_v2.predict([[r1, r2]])\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse_v1 = mean_squared_error(y_v1, predicted_v1)\n",
    "mse_v2 = mean_squared_error(y_v2, predicted_v2)\n",
    "\n",
    "print(\"Predicted v1:\", predicted_v1[0])\n",
    "print(\"Predicted v2:\", predicted_v2[0])\n",
    "print(\"Mean Squared Error for v1:\", mse_v1)\n",
    "print(\"Mean Squared Error for v2:\", mse_v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140e0ef0-8ee6-4473-b8fe-28380d0e8ddd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Optimizing Algorithms and Use Cases:**\n",
    "\n",
    "**1. AdaGrad:**\n",
    "\n",
    "* **Use Case 1: Sparse Features**\n",
    "  - AdaGrad excels when dealing with datasets containing features that rarely update significantly. Its cumulative learning rate adaptation helps prevent frequent updates from diminishing the impact on less frequent ones.\n",
    "  - Example: Recommender systems often have user-item interactions where some users interact with only a small subset of items. AdaGrad can effectively train the model for these users.\n",
    "* **Use Case 2: Non-stationary or Time-Varying Problems**\n",
    "  - In scenarios where the underlying distribution of data changes over time, AdaGrad's continuously adapting learning rates can be beneficial. However, it's crucial to monitor the learning rates as they can eventually become very small.\n",
    "  - Example: Financial forecasting where market conditions are constantly evolving.\n",
    "\n",
    "**2. RMSProp:**\n",
    "\n",
    "* **Use Case 1: Faster Convergence than Standard SGD**\n",
    "  - RMSProp addresses the issue of SGD's potentially slow convergence in certain situations by incorporating a decaying average of squared gradients. This leads to smoother updates and often faster convergence.\n",
    "  - Example: Image classification tasks where standard SGD might struggle to find the optimal solution efficiently.\n",
    "* **Use Case 2: Balancing AdaGrad's Adaptability with Stability**\n",
    "  - RMSProp offers a balance between AdaGrad's aggressive learning rate adaptation and SGD's potentially slow convergence. It's a good choice when you need an algorithm that adapts to changing data distributions but avoids overly diminishing learning rates.\n",
    "  - Example: Natural language processing (NLP) tasks where the vocabulary might contain rare words with less frequent updates.\n",
    "\n",
    "**3. RMSProp with Nesterov Momentum (NRMSProp):**\n",
    "\n",
    "* **Use Case 1: Improved Convergence over Standard RMSProp**\n",
    "  - NRMSProp incorporates Nesterov momentum, which can help the algorithm escape local minima and reach better solutions faster. It often converges more quickly than standard RMSProp.\n",
    "  - Example: Deep neural network training where standard RMSProp might get stuck in suboptimal regions of the loss landscape.\n",
    "* **Use Case 2: Complex or Deep Learning Architectures**\n",
    "  - NRMSProp's combination of adaptive learning rates and momentum can be particularly advantageous for complex models that require careful navigation in high-dimensional spaces.\n",
    "  - Example: Training generative adversarial networks (GANs) or recurrent neural networks (RNNs) for tasks like image generation or language translation.\n",
    "\n",
    "**4. Adam:**\n",
    "\n",
    "* **Use Case 1: General-Purpose Optimizer with Adaptive Learning Rates**\n",
    "  - Adam is widely considered a powerful and versatile optimizer due to its combination of momentum and adaptive learning rates. It often performs well across various deep learning tasks, making it a popular default choice.\n",
    "  - Example: A wide range of deep learning problems, including computer vision, NLP, and time series forecasting.\n",
    "* **Use Case 2: Fine-Tuning Pre-trained Models**\n",
    "  - Adam can be effective when fine-tuning pre-trained models on new datasets. Its adaptive learning rates help the model adjust to the specific data it's being fine-tuned on.\n",
    "  - Example: Transfer learning scenarios where you're adapting a pre-trained image classification model for a new set of image categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1182f94c-b4a9-478e-a898-05e24a61e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment Linear Regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fccb4d4-0c29-495f-850e-a8d4a7cb439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "R1 = np.random.uniform(1, 10000, 100)\n",
    "R2 = np.random.uniform(1, 10000, 100)\n",
    "Vt = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8631970e-8359-4177-9316-9e30be194a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "V1 = Vt * (R1 / (R1 + R2))\n",
    "V2 = Vt * (R2 / (R1 + R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "399b327e-1a0a-44ba-b648-dfedcfe6a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'R1' : R1,\n",
    "    'R2' : R2,\n",
    "    'V1' : V1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e58e61c6-d2d4-46ff-94f1-bd24557f4003",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['R1','R2']]\n",
    "y = data['V1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6aa58823-bc69-4e54-ab27-c60fabf0b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "571bb282-d95e-428a-883d-aa86c65c1c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13a44d22-3971-4734-bc97-898c36579bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.0066365 , -0.00621271]), 57.151037551471404, 50.41004897634889)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "model.coef_, model.intercept_, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5467a3f8-92b6-4e85-ae6f-e77ee647cb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             R1           R2\n",
      "83  6925.028722  2379.690321\n",
      "53  1021.346063  6155.980083\n",
      "70  9764.618191  5210.845025\n",
      "45  6706.708058  7039.181947\n",
      "44  6668.000388  8062.133696\n",
      "39  6818.521171  4314.752936\n",
      "22  4615.332143  9560.880264\n",
      "80  3180.513811  1647.776871\n",
      "10  7917.458656  4471.806661\n",
      "0   5488.586226  6778.487551\n",
      "18  7781.789353  8817.471883\n",
      "30  2646.291565  6180.536275\n",
      "73  6048.850352   186.199423\n",
      "33  5684.771055  2983.524977\n",
      "90  3186.370956  3982.812401\n",
      "4   4237.124339  2488.282682\n",
      "76  2828.786819  3454.171455\n",
      "77  1202.845416  9280.884853\n",
      "12  5680.877566  6995.093274\n",
      "31  7742.562661  4288.258241\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3efdac-d09b-4d74-bcf2-796eff8db7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
